{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import data\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "full = train.drop('label', axis=1).append(test)\n",
    "labels = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b4863f610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sanity check\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHECK = 2\n",
    "\n",
    "def show_first_n_images(data, n):\n",
    "    reshaped_img = [np.array(data.iloc[i,].reshape((IMAGE_SIZE,IMAGE_SIZE))) for i in range(n)]\n",
    "\n",
    "    ax_tuple = ('ax' + str(i) for i in xrange(n))\n",
    "    _, ax_tuple = plt.subplots(1, n)\n",
    "    for i in xrange(n):\n",
    "        ax_tuple[i].imshow(reshaped_img[i], cmap=plt.cm.Greys);\n",
    "\n",
    "show_first_n_images(full, NUM_CHECK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADQdJREFUeJzt3X+IXfWZx/HPJz8RUyRuZkOwutMtsiDKJnIJQrQkqa0m\nFmIRh+SPGkU2QSpupUiDBSv4jyymJchSSDU0Xbq2q6kaJXTrxp8VqRmD1djU1ZUJTRiTCRZjIjEx\nefaPOZZR554Z7z33njt53i8Y5t7znB8Ph3zm3Hu+N/friBCAfKbV3QCAehB+ICnCDyRF+IGkCD+Q\nFOEHkiL8QFKEH0iK8ANJzejmwebNmxf9/f3dPCSQytDQkA4fPuzJrNtW+G1fLWmTpOmSHoiIe8vW\n7+/v1+DgYDuHBFCi0WhMet2WX/bbni7p3yWtkHSRpDW2L2p1fwC6q533/IslvR0R70TECUm/krSq\nmrYAdFo74T9P0l/GPN9fLPsU2+tsD9oeHBkZaeNwAKrU8bv9EbE5IhoR0ejr6+v04QBMUjvhPyDp\n/DHPv1wsAzAFtBP+XZIutP0V27MkrZa0vZq2AHRay0N9EfGx7Vsl/bdGh/q2RMQblXUGoKPaGueP\niB2SdlTUC4Au4uO9QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k\nRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyTV1Sm6gW4aGBhoWnv44YdLt3366adL68uWLWup\np17ClR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmprnN/2kKQPJJ2S9HFENKpoCpiM6667rrT+xBNP\nNK1Nm1Z+3bPdUk9TSRUf8lkWEYcr2A+ALuJlP5BUu+EPSb+z/YrtdVU0BKA72n3Zf3lEHLD995Ke\nsv3niHh+7ArFH4V1knTBBRe0eTgAVWnryh8RB4rfhyQ9KmnxOOtsjohGRDT6+vraORyACrUcfttn\n2/7SJ48lfVPSnqoaA9BZ7bzsny/p0WJIZIak/4yI31bSFYCOazn8EfGOpH+usBfgUx544IHS+o4d\nO0rrp06dalq75ZZbSrddsmRJaf1MwFAfkBThB5Ii/EBShB9IivADSRF+ICm+uhu12bVrV2n9tttu\nK62fOHGitH7ZZZc1rW3cuLF025kzZ5bWzwRc+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcb50VFH\njhxpWrv99ttLt/3oo49K6xN9M9T999/ftDZ79uzSbTPgyg8kRfiBpAg/kBThB5Ii/EBShB9IivAD\nSTHOj7bs27evtL569eqmtZdffrmtYz/yyCOl9UsvvbSt/Z/puPIDSRF+ICnCDyRF+IGkCD+QFOEH\nkiL8QFITjvPb3iLpW5IORcTFxbJzJf1aUr+kIUkDEfHXzrWJujz77LOl9eXLl5fWbTetzZ07t3Tb\n66+/vrTeaDRK6yg3mSv/zyVd/ZllGyTtjIgLJe0sngOYQiYMf0Q8L+m9zyxeJWlr8XirpGsr7gtA\nh7X6nn9+RAwXj9+VNL+ifgB0Sds3/CIiJEWzuu11tgdtD46MjLR7OAAVaTX8B20vkKTi96FmK0bE\n5ohoRERjoi9cBNA9rYZ/u6S1xeO1kh6vph0A3TJh+G0/JOklSf9ke7/tmyXdK+kbtt+SdGXxHMAU\nMuE4f0SsaVL6esW9oAbHjh0rrW/Y0LlR3BtvvLG0ft9993Xs2OATfkBahB9IivADSRF+ICnCDyRF\n+IGk+OruM9zx48dL61deeWVpfdeuXW0d/5xzzmlaGxgYaGvfaA9XfiApwg8kRfiBpAg/kBThB5Ii\n/EBShB9IinH+M9zJkydL6+1Okz2R4eHhprXZs2d39Ngox5UfSIrwA0kRfiApwg8kRfiBpAg/kBTh\nB5JinP8M8OGHHzatXXPNNaXbjs621rqrrrqqtD59+vS29o/O4coPJEX4gaQIP5AU4QeSIvxAUoQf\nSIrwA0lNOM5ve4ukb0k6FBEXF8vulvQvkkaK1e6MiB2dahLl7rjjjqa1F198sXRb26X1FStWlNYf\ne+yx0vqMGXyUpFdN5sr/c0lXj7P8JxGxsPgh+MAUM2H4I+J5Se91oRcAXdTOe/5bbb9me4vtuZV1\nBKArWg3/TyV9VdJCScOSNjZb0fY624O2B0dGRpqtBqDLWgp/RByMiFMRcVrSzyQtLll3c0Q0IqLR\n19fXap8AKtZS+G0vGPP025L2VNMOgG6ZzFDfQ5KWSppne7+kH0laanuhpJA0JGl9B3sE0AEThj8i\n1oyz+MEO9IImyv6/viTt3bu35X3PmjWrtH7PPfeU1hnHn7r4hB+QFOEHkiL8QFKEH0iK8ANJEX4g\nKcZpesCxY8dK6zfddFNp/bnnnmtaO+uss0q3ffLJJ0vrixYtKq1j6uLKDyRF+IGkCD+QFOEHkiL8\nQFKEH0iK8ANJMc7fA5555pnS+rZt21re90RTaC9durTlfWNq48oPJEX4gaQIP5AU4QeSIvxAUoQf\nSIrwA0kxzt8FL7zwQmn9hhtuaGv/K1eubFrbunVrW/vGmYsrP5AU4QeSIvxAUoQfSIrwA0kRfiAp\nwg8kNeE4v+3zJf1C0nxJIWlzRGyyfa6kX0vqlzQkaSAi/tq5VnvX8ePHS+vr168vrb///vttHf+u\nu+5qWpszZ05b+8aZazJX/o8lfT8iLpJ0maTv2r5I0gZJOyPiQkk7i+cApogJwx8RwxGxu3j8gaS9\nks6TtErSJx8f2yrp2k41CaB6X+g9v+1+SYsk/UHS/IgYLkrvavRtAYApYtLhtz1H0jZJ34uII2Nr\nEREavR8w3nbrbA/aHhwZGWmrWQDVmVT4bc/UaPB/GRG/KRYftL2gqC+QdGi8bSNic0Q0IqLR19dX\nRc8AKjBh+G1b0oOS9kbEj8eUtktaWzxeK+nx6tsD0CmT+S+9SyR9R9Lrtl8tlt0p6V5J/2X7Zkn7\nJA10psXe99JLL5XW33zzzY4e/+jRox3dP85ME4Y/In4vyU3KX6+2HQDdwif8gKQIP5AU4QeSIvxA\nUoQfSIrwA0nx1d0VmDGj/DROm1b+N/b06dOl9enTp5fW9+zZ07S2bNmy0m2RF1d+ICnCDyRF+IGk\nCD+QFOEHkiL8QFKEH0iKcf4KXHHFFaX1Sy65pLR+8uTJ0vqmTZtK68uXLy+tA+Phyg8kRfiBpAg/\nkBThB5Ii/EBShB9IivADSTHO3wW7d++uuwXgc7jyA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSE4bf\n9vm2n7H9J9tv2P7XYvndtg/YfrX4Wdn5dgFUZTIf8vlY0vcjYrftL0l6xfZTRe0nEXFf59oD0CkT\nhj8ihiUNF48/sL1X0nmdbgxAZ32h9/y2+yUtkvSHYtGttl+zvcX23CbbrLM9aHtwZGSkrWYBVGfS\n4bc9R9I2Sd+LiCOSfirpq5IWavSVwcbxtouIzRHRiIhGX19fBS0DqMKkwm97pkaD/8uI+I0kRcTB\niDgVEacl/UzS4s61CaBqk7nbb0kPStobET8es3zBmNW+Lan5VLEAes5k7vYvkfQdSa/bfrVYdqek\nNbYXSgpJQ5LWd6RDAB0xmbv9v5fkcUo7qm8HQLfwCT8gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSjojuHcwekbRvzKJ5kg53rYEvpld769W+JHprVZW9/UNE\nTOr78roa/s8d3B6MiEZtDZTo1d56tS+J3lpVV2+87AeSIvxAUnWHf3PNxy/Tq731al8SvbWqlt5q\nfc8PoD51X/kB1KSW8Nu+2vabtt+2vaGOHpqxPWT79WLm4cGae9li+5DtPWOWnWv7KdtvFb/HnSat\npt56Yubmkpmlaz13vTbjdddf9tueLul/JX1D0n5JuyStiYg/dbWRJmwPSWpERO1jwra/JumopF9E\nxMXFsn+T9F5E3Fv84ZwbET/okd7ulnS07pmbiwllFoydWVrStZJuVI3nrqSvAdVw3uq48i+W9HZE\nvBMRJyT9StKqGvroeRHxvKT3PrN4laStxeOtGv3H03VNeusJETEcEbuLxx9I+mRm6VrPXUlftagj\n/OdJ+suY5/vVW1N+h6Tf2X7F9rq6mxnH/GLadEl6V9L8OpsZx4QzN3fTZ2aW7plz18qM11Xjht/n\nXR4Rl0paIem7xcvbnhSj79l6abhmUjM3d8s4M0v/TZ3nrtUZr6tWR/gPSDp/zPMvF8t6QkQcKH4f\nkvSoem/24YOfTJJa/D5Ucz9/00szN483s7R64Nz10ozXdYR/l6QLbX/F9ixJqyVtr6GPz7F9dnEj\nRrbPlvRN9d7sw9slrS0er5X0eI29fEqvzNzcbGZp1Xzuem7G64jo+o+klRq94/9/kn5YRw9N+vpH\nSX8sft6ouzdJD2n0ZeBJjd4buVnS30naKektSf8j6dwe6u0/JL0u6TWNBm1BTb1drtGX9K9JerX4\nWVn3uSvpq5bzxif8gKS44QckRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKn/B8WS+qa3Q7UKAAAA\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b7bfc2e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# normalize data\n",
    "\n",
    "# each pixel is encoded as an integer between 0 and 255\n",
    "# convert to floats and rescale them to be centered around\n",
    "# 0, from [-0.5, 0.5]\n",
    "PIXEL_DEPTH = 255\n",
    "\n",
    "def normalize_data(data):\n",
    "    '''Returns a normalized 4d numpy tensor from a pandas data frame\n",
    "    [image index, y, x, channels]\n",
    "    '''\n",
    "    scaled = data.astype(np.float32)\n",
    "    scaled = (scaled - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "\n",
    "    # reshape to a set of n images, each IMAGE_SIZE*IMAGE_SIZE rather than\n",
    "    # each image being represented by a vector of size IMAGE_SIZE^2\n",
    "    reshaped = scaled.values.reshape(70000, IMAGE_SIZE, IMAGE_SIZE, 1).astype(np.float32)\n",
    "    return reshaped\n",
    "\n",
    "full = normalize_data(full)\n",
    "train_data = full[:42000,]\n",
    "labels = np.array(labels)\n",
    "test_data = full[42000:,]\n",
    "\n",
    "# replot to make sure data isn't mangled\n",
    "plt.imshow(full[0].reshape(28,28), cmap=plt.cm.Greys);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training labels shape', (42000, 10))\n",
      "('First label vector', array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32))\n",
      "('Second label vector', array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to dense 1-hot representation of 10 digits\n",
    "# e.g. 5 is represented by the vector [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "\n",
    "NUM_LABELS = 10 # one for each digit 0..9\n",
    "train_labels = (np.arange(NUM_LABELS) == labels[:, None]).astype(np.float32)\n",
    "\n",
    "print('Training labels shape', train_labels.shape)\n",
    "print('First label vector', train_labels[0])\n",
    "print('Second label vector', train_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Validation shape', (5000, 28, 28, 1))\n",
      "('Train size', 37000)\n"
     ]
    }
   ],
   "source": [
    "# Create a validation set from training data to help with our model\n",
    "\n",
    "VALIDATION_SIZE = 5000\n",
    "\n",
    "validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, :, :, :]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "print('Validation shape', validation_data.shape)\n",
    "print('Train size', train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define our tensorflow variables that will hold weights\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 42\n",
    "NUM_CHANNELS = 1\n",
    "SEED = 42\n",
    "\n",
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "train_labels_node = tf.placeholder(tf.float32,\n",
    "                                   shape=(BATCH_SIZE, NUM_LABELS))\n",
    "\n",
    "validation_data_node = tf.constant(validation_data)\n",
    "test_data_node = tf.constant(test_data)\n",
    "\n",
    "conv1_weights = tf.Variable(\n",
    "    tf.truncated_normal([5, 5, NUM_CHANNELS, 32], # 5x5 filter, depth 32\n",
    "                        stddev=0.1,\n",
    "                        seed=SEED))\n",
    "conv1_biases = tf.Variable(tf.zeros([32]))\n",
    "\n",
    "conv2_weights = tf.Variable(\n",
    "    tf.truncated_normal([5, 5, 32, 64],\n",
    "                        stddev=0.1,\n",
    "                        seed=SEED))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "\n",
    "fc1_weights = tf.Variable(\n",
    "    tf.truncated_normal([IMAGE_SIZE / 4 * IMAGE_SIZE / 4 * 64, 512],\n",
    "                        stddev=0.1,\n",
    "                        seed=SEED))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512]))\n",
    "\n",
    "fc2_weights = tf.Variable(\n",
    "    tf.truncated_normal([512, NUM_LABELS],\n",
    "                        stddev=0.1,\n",
    "                        seed=SEED))\n",
    "fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS]))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Define our basic model graph structure\n",
    "\n",
    "def model(data, train=False):\n",
    "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "    # the same size as the input). Note that {strides} is a 4D array whose\n",
    "    # shape matches the data layout: [image index, y, x, depth].\n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1,1,1,1],\n",
    "                        padding='SAME')\n",
    "    \n",
    "    # bias and rectified linear non-linearity\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    \n",
    "    # Max pooling. The kernel size spec ksize also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1,2,2,1],\n",
    "                          strides=[1,2,2,1],\n",
    "                          padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1,1,1,1],\n",
    "                        padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1,2,2,1],\n",
    "                          strides=[1,2,2,1],\n",
    "                          padding='SAME')\n",
    "\n",
    "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "    # fully connected layers.\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool,\n",
    "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "  \n",
    "    # Fully connected layer. Note that the '+' operation automatically\n",
    "    # broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "  \n",
    "    # Add a 50% dropout during training only. Dropout also scales\n",
    "    # activations such that no rescaling is needed at evaluation time.\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Create several copies of the model graph for training, \n",
    "# testing, and validation\n",
    "\n",
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits, train_labels_node))\n",
    "\n",
    "# L2 regularization for the fully connected parameters\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "                tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "# Set up a variable that is incremented once per batch and\n",
    "# controls the learning rate decay\n",
    "batch = tf.Variable(0)\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.01,                  # Base learning rate\n",
    "    batch * BATCH_SIZE,    # Current index into the dataset\n",
    "    train_size,            # Decay step\n",
    "    0.95,                  # Decay rate\n",
    "    staircase=True)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                       0.9).minimize(loss,\n",
    "                                                     global_step=batch)\n",
    "\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "validation_prediction = tf.nn.softmax(model(validation_data_node))\n",
    "test_prediction = tf.nn.softmax(model(test_data_node))\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-f1164f20b979>:6 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# Create a new interactive session\n",
    "s = tf.InteractiveSession()\n",
    "s.as_default()\n",
    "\n",
    "# Initialize all the variables\n",
    "tf.initialize_all_variables().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    correct = np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "    total = predictions.shape[0]\n",
    "\n",
    "    error = 100.0 - (100 * float(correct) / float(total))\n",
    "    \n",
    "    confusions = np.zeros([10,10], np.float32)\n",
    "    bundled = zip(np.argmax(predictions, 1), np.argmax(labels, 1))\n",
    "    for predicted, actual in bundled:\n",
    "        confusions[predicted, actual] += 1\n",
    "        \n",
    "    return error, confusions\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Training steps\n",
    "\n",
    "steps = int(train_size / BATCH_SIZE)\n",
    "for step in xrange(steps):\n",
    "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "    batch_data = train_data[offset:(offset + BATCH_SIZE), :, :, :]\n",
    "    batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "    \n",
    "    feed_dict = {train_data_node: batch_data,\n",
    "                 train_labels_node: batch_labels}\n",
    "    \n",
    "    _, l, lr, predictions = s.run(\n",
    "        [optimizer, loss, learning_rate, train_prediction],\n",
    "        feed_dict=feed_dict)\n",
    "    \n",
    "    if step % (BATCH_SIZE *2):\n",
    "        error, _ = error_rate(predictions, batch_labels)\n",
    "        print('Step %d of %d' % (step, steps))\n",
    "        print('Mini-batch loss: %.5f Error: %.5f Learning rate: %.5f' % (l, error, lr))\n",
    "        print('Validation error: %.1f%%' % error_rate(\n",
    "            validation_prediction.eval(), validation_labels)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = test_prediction.eval()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write output to csv\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "submission = pd.DataFrame({\n",
    "        'ImageId': np.arange(1, len(pred_labels) + 1),\n",
    "        'Label': pred_labels\n",
    "    })\n",
    "\n",
    "submission.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
